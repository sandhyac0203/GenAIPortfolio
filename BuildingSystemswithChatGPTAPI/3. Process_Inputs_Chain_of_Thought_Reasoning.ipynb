{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzQIGBCiCI2oD0KNObC0YM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandhyac0203/GenAIPortfolio/blob/main/3.%20Process_Inputs_Chain_of_Thought_Reasoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLPvjNMZC2d8",
        "outputId": "fbe09142-7c85-44c3-a070-d7b8f315f524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "#!pip install openai\n",
        "#!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "client = openai.OpenAI(api_key=\"*\")"
      ],
      "metadata": {
        "id": "_5zB6TqpF2J_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper function (chat format)\n",
        "\n",
        "def get_completion_from_messages(messages,model=\"gpt-3.5-turbo\",temperature=0, max_tokens=500):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # this is the degree of randomness of the model's output\n",
        "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "ChuC44voGd_l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chain of thought prompting\n",
        "delimiter = \"####\"\n",
        "system_message = f\"\"\"\n",
        "Follow these steps to answer the customer queries.\n",
        "The customer query will be delimited with four hashtags,\\\n",
        "i.e. {delimiter}.\n",
        "\n",
        "Step 1:{delimiter} First decide whether the user is \\\n",
        "asking a question about a specific product or products. \\\n",
        "Product cateogry doesn't count.\n",
        "\n",
        "Step 2:{delimiter} If the user is asking about \\\n",
        "specific products, identify whether \\\n",
        "the products are in the following list.\n",
        "All available products:\n",
        "1. Product: TechPro Ultrabook\n",
        "   Category: Computers and Laptops\n",
        "   Brand: TechPro\n",
        "   Model Number: TP-UB100\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.5\n",
        "   Features: 13.3-inch display, 8GB RAM, 256GB SSD, Intel Core i5 processor\n",
        "   Description: A sleek and lightweight ultrabook for everyday use.\n",
        "   Price: $799.99\n",
        "\n",
        "2. Product: BlueWave Gaming Laptop\n",
        "   Category: Computers and Laptops\n",
        "   Brand: BlueWave\n",
        "   Model Number: BW-GL200\n",
        "   Warranty: 2 years\n",
        "   Rating: 4.7\n",
        "   Features: 15.6-inch display, 16GB RAM, 512GB SSD, NVIDIA GeForce RTX 3060\n",
        "   Description: A high-performance gaming laptop for an immersive experience.\n",
        "   Price: $1199.99\n",
        "\n",
        "3. Product: PowerLite Convertible\n",
        "   Category: Computers and Laptops\n",
        "   Brand: PowerLite\n",
        "   Model Number: PL-CV300\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.3\n",
        "   Features: 14-inch touchscreen, 8GB RAM, 256GB SSD, 360-degree hinge\n",
        "   Description: A versatile convertible laptop with a responsive touchscreen.\n",
        "   Price: $699.99\n",
        "\n",
        "4. Product: TechPro Desktop\n",
        "   Category: Computers and Laptops\n",
        "   Brand: TechPro\n",
        "   Model Number: TP-DT500\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.4\n",
        "   Features: Intel Core i7 processor, 16GB RAM, 1TB HDD, NVIDIA GeForce GTX 1660\n",
        "   Description: A powerful desktop computer for work and play.\n",
        "   Price: $999.99\n",
        "\n",
        "5. Product: BlueWave Chromebook\n",
        "   Category: Computers and Laptops\n",
        "   Brand: BlueWave\n",
        "   Model Number: BW-CB100\n",
        "   Warranty: 1 year\n",
        "   Rating: 4.1\n",
        "   Features: 11.6-inch display, 4GB RAM, 32GB eMMC, Chrome OS\n",
        "   Description: A compact and affordable Chromebook for everyday tasks.\n",
        "   Price: $249.99\n",
        "\n",
        "Step 3:{delimiter} If the message contains products \\\n",
        "in the list above, list any assumptions that the \\\n",
        "user is making in their \\\n",
        "message e.g. that Laptop X is bigger than \\\n",
        "Laptop Y, or that Laptop Z has a 2 year warranty.\n",
        "\n",
        "Step 4:{delimiter}: If the user made any assumptions, \\\n",
        "figure out whether the assumption is true based on your \\\n",
        "product information.\n",
        "\n",
        "Step 5:{delimiter}: First, politely correct the \\\n",
        "customer's incorrect assumptions if applicable. \\\n",
        "Only mention or reference products in the list of \\\n",
        "5 available products, as these are the only 5 \\\n",
        "products that the store sells. \\\n",
        "Answer the customer in a friendly tone.\n",
        "\n",
        "Use the following format:\n",
        "Step 1:{delimiter} <step 1 reasoning>\n",
        "Step 2:{delimiter} <step 2 reasoning>\n",
        "Step 3:{delimiter} <step 3 reasoning>\n",
        "Step 4:{delimiter} <step 4 reasoning>\n",
        "Response to user:{delimiter} <response to customer>\n",
        "\n",
        "Make sure to include {delimiter} to separate every step.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ew0-_br6GqiT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = f\"\"\"\n",
        "by how much is the BlueWave Chromebook more expensive \\\n",
        "than the TechPro Desktop\"\"\"\n",
        "\n",
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content': system_message},\n",
        "{'role':'user',\n",
        " 'content': f\"{delimiter}{user_message}{delimiter}\"},\n",
        "]\n",
        "\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpvTciMuG9-E",
        "outputId": "b94d9dd9-4680-4378-c215-6b4ff21db395"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:#### The user is comparing the prices of two specific products.\n",
            "Step 2:#### The user is comparing the BlueWave Chromebook and the TechPro Desktop.\n",
            "Step 3:#### The assumption made by the user is that the BlueWave Chromebook is more expensive than the TechPro Desktop.\n",
            "Step 4:#### The TechPro Desktop is priced at $999.99, and the BlueWave Chromebook is priced at $249.99. Therefore, the BlueWave Chromebook is $750 cheaper than the TechPro Desktop.\n",
            "Response to user:#### The BlueWave Chromebook is actually $750 cheaper than the TechPro Desktop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = f\"\"\"\n",
        "do you sell tvs\"\"\"\n",
        "messages =  [\n",
        "{'role':'system',\n",
        " 'content': system_message},\n",
        "{'role':'user',\n",
        " 'content': f\"{delimiter}{user_message}{delimiter}\"},\n",
        "]\n",
        "response = get_completion_from_messages(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okm7CmVBG-x1",
        "outputId": "b7f7cd0e-283d-42cf-b841-f3f351ed09e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:#### The user is asking a general question about whether the store sells TVs, not a specific product question. Therefore, the user is not asking about a specific product.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inner monologue\n",
        "#Since we asked the LLM to separate its reasoning steps by a delimiter, we can hide the chain-of-thought reasoning from the final output that the user sees.\n",
        "try:\n",
        "    final_response = response.split(delimiter)[-1].strip()\n",
        "except Exception as e:\n",
        "    final_response = \"Sorry, I'm having trouble right now, please try asking another question.\"\n",
        "\n",
        "print(final_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax1xqOi1HAvE",
        "outputId": "6025be00-27ac-4d41-bcd0-323958ea092b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The user is asking a general question about whether the store sells TVs, not a specific product question. Therefore, the user is not asking about a specific product.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbe0X-jqHL6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
